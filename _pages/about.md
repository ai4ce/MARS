---
layout: about
title: Overview
permalink: /
subtitle:


news: true # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

---

<img src="./assets/img/teaser.jpg" alt="drawing" style="width:1200px;" class="center"/>

---

In collaboration with the self-driving company [<span style="font-weight: bold; color:#369040">May Mobility</span>](https://maymobility.com/), we present the MARS dataset which unifies scenarios that enable multiagent, multitraversal, and multimodal autonomous vehicle research. 

MARS is collected with a fleet of autonomous vehicles driving within a certain geographical area. 
Each vehicle has its own route and different vehicles may appear at nearby locations. 
Each vehicle is equipped with a LiDAR and surround-view RGB cameras.

We curate two subsets in MARS: one facilitates collaborative driving with multiple vehicles simultaneously present at the same location, and the other enables memory retrospection through asynchronous traversals of the same location by multiple vehicles. 
We conduct experiments in place recognition and neural reconstruction. 
More importantly, MARS introduces new research opportunities and challenges such as multitraversal 3D reconstruction, multiagent perception, and unsupervised object discovery.

---
